"""
Smart Query Engine
===================

LLM-driven query engine that interprets natural language questions
and dynamically generates database queries.

Flow:
1. User asks question in natural language
2. LLM analyzes question and generates query plan
3. Query plan executed against database
4. Results fed back to LLM for response generation

This replaces hardcoded pattern matching with flexible LLM reasoning.
"""

from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple
from datetime import date, datetime, timedelta
from sqlalchemy.orm import Session
from sqlalchemy import func, and_, or_, text
import json
import logging
import models


@dataclass
class QueryPlan:
    """Structured query plan generated by LLM."""
    query_type: str  # "activity_filter", "comparison", "trend", "aggregate"
    description: str  # What we're looking for
    filters: Dict[str, Any] = field(default_factory=dict)
    aggregations: List[str] = field(default_factory=list)
    time_range_days: Optional[int] = None
    limit: int = 50
    comparison_filters: Optional[Dict[str, Any]] = None  # For A vs B queries


SCHEMA_CONTEXT = """
# DATABASE SCHEMA

## activities table (her koÅŸu/antrenman)
- distance: float (metre)
- duration: float (saniye)
- average_hr: int (bpm)
- max_hr: int (bpm)
- weather_temp: float (celsius, null olabilir)
- elevation_gain: float (metre)
- local_start_date: date
- activity_name: string
- vo2_max: int (aktivite sÄ±rasÄ±nda Ã¶lÃ§Ã¼len)
- avg_cadence: int (spm)
- avg_stride_length: float (cm)
- rpe: int (perceived exertion)

## activity_streams table (GPS verileri, saniye saniye)
- altitude: float (metre - rakÄ±m)
- heart_rate: int
- speed: float (m/s)
- cadence: int

## health tables
- sleep_logs: sleep_score, deep_seconds, rem_seconds
- hrv_logs: last_night_avg, status
- stress_logs: avg_stress, max_stress

# QUERY FILTER OPERATORS
- gt: greater than (>)
- lt: less than (<)
- gte: greater than or equal (>=)
- lte: less than or equal (<=)
- eq: equals (=)
- contains: string contains (ILIKE)
- is_not_null: field is not null
"""

QUERY_ANALYZER_PROMPT = """
Sen bir veritabanÄ± sorgu planlayÄ±cÄ±sÄ±sÄ±n. KullanÄ±cÄ±nÄ±n sorusunu analiz et ve hangi verilerinin gerektiÄŸini belirle.

{schema}

# KULLANICI SORUSU
{question}

# TALÄ°MAT
Bu soruyu cevaplamak iÃ§in veritabanÄ±ndan hangi verileri Ã§ekmemiz gerektiÄŸini JSON olarak dÃ¶ndÃ¼r.

Sorgu planÄ± yapÄ±sÄ±:
{{
    "query_type": "activity_filter" | "comparison" | "trend" | "aggregate",
    "description": "Neyi sorguladÄ±ÄŸÄ±mÄ±zÄ±n kÄ±sa aÃ§Ä±klamasÄ±",
    "filters": {{
        "column_name": {{"operator": value}}
    }},
    "aggregations": ["count", "avg_pace", "avg_hr", "total_distance", "avg_temp"],
    "time_range_days": null veya gÃ¼n sayÄ±sÄ±,
    "limit": 50,
    "comparison_filters": null veya karÅŸÄ±laÅŸtÄ±rma grubu filtreleri
}}

# Ã–RNEKLER

Soru: "SÄ±cak havalarda koÅŸularÄ±m nasÄ±lmÄ±ÅŸ?"
{{
    "query_type": "comparison",
    "description": "SÄ±cak havalarda (>25Â°C) vs normal koÅŸullar performans karÅŸÄ±laÅŸtÄ±rmasÄ±",
    "filters": {{"weather_temp": {{"gt": 25}}}},
    "aggregations": ["count", "avg_pace", "avg_hr", "avg_distance"],
    "comparison_filters": {{"weather_temp": {{"lte": 25}}}}
}}

Soru: "YÃ¼ksek rakÄ±mda koÅŸularÄ±m"
{{
    "query_type": "activity_filter",
    "description": "YÃ¼ksek rakÄ±mda (>1000m) koÅŸular",
    "filters": {{"altitude_avg": {{"gt": 1000}}}},
    "aggregations": ["count", "avg_pace", "avg_hr"]
}}

Soru: "Uzun koÅŸularÄ±m nasÄ±l gidiyor?"
{{
    "query_type": "activity_filter", 
    "description": "Uzun koÅŸular (15km+)",
    "filters": {{"distance": {{"gt": 15000}}}},
    "aggregations": ["count", "avg_pace", "avg_hr"]
}}

SADECE JSON DÃ–NDÃœR, baÅŸka bir ÅŸey yazma.
"""


class SmartQueryEngine:
    """LLM-driven query engine for flexible question answering."""
    
    def __init__(self, db: Session, llm_client):
        self.db = db
        self.llm = llm_client
    
    def analyze_and_answer(self, user_id: int, question: str) -> Tuple[str, Dict]:
        """
        Main entry point: analyze question, execute query, generate response.
        
        Returns:
            Tuple of (response text, debug info)
        """
        # Step 1: Generate query plan
        plan = self._generate_query_plan(question)
        
        if not plan:
            return "Bu soruyu anlamakta zorlandÄ±m. LÃ¼tfen daha spesifik sorabilir misin?", {}
        
        # Step 2: Execute query
        results = self._execute_query(user_id, plan)
        
        # Step 3: Generate response with data
        response = self._generate_response(question, plan, results)
        
        debug = {
            "query_type": plan.query_type,
            "description": plan.description,
            "filters": plan.filters,
            "result_count": results.get("count", 0)
        }
        
        return response, debug
    
    def _generate_query_plan(self, question: str) -> Optional[QueryPlan]:
        """Use LLM to generate query plan from natural language."""
        prompt = QUERY_ANALYZER_PROMPT.format(
            schema=SCHEMA_CONTEXT,
            question=question
        )
        
        try:
            response = self.llm.generate(prompt, max_tokens=500)
            
            # Parse JSON from response
            text = response.text.strip()
            # Handle markdown code blocks
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                text = text.split("```")[1].split("```")[0].strip()
            
            plan_dict = json.loads(text)
            
            return QueryPlan(
                query_type=plan_dict.get("query_type", "activity_filter"),
                description=plan_dict.get("description", "Aktivite sorgusu"),
                filters=plan_dict.get("filters", {}),
                aggregations=plan_dict.get("aggregations", ["count"]),
                time_range_days=plan_dict.get("time_range_days"),
                limit=plan_dict.get("limit", 50),
                comparison_filters=plan_dict.get("comparison_filters")
            )
        except Exception as e:
            logging.error(f"Query plan generation failed: {e}")
            return None
    
    def _execute_query(self, user_id: int, plan: QueryPlan) -> Dict:
        """Execute query plan against database."""
        
        # Build base query
        base_query = self.db.query(models.Activity).filter(
            models.Activity.user_id == user_id
        )
        
        # Apply time range
        if plan.time_range_days:
            start_date = date.today() - timedelta(days=plan.time_range_days)
            base_query = base_query.filter(
                models.Activity.local_start_date >= start_date
            )
        
        # Apply filters
        filtered_query = self._apply_filters(base_query, plan.filters)
        
        # Execute main query
        main_results = self._aggregate_results(filtered_query.all(), plan.aggregations)
        
        # Execute comparison query if needed
        comparison_results = None
        if plan.comparison_filters:
            comp_query = self._apply_filters(base_query, plan.comparison_filters)
            comparison_results = self._aggregate_results(comp_query.all(), plan.aggregations)
        
        return {
            "main": main_results,
            "comparison": comparison_results,
            "description": plan.description
        }
    
    def _apply_filters(self, query, filters: Dict):
        """Apply filters to query."""
        for column, condition in filters.items():
            if not isinstance(condition, dict):
                continue
            
            # Map column names to model attributes
            column_map = {
                "distance": models.Activity.distance,
                "duration": models.Activity.duration,
                "average_hr": models.Activity.average_hr,
                "max_hr": models.Activity.max_hr,
                "weather_temp": models.Activity.weather_temp,
                "elevation_gain": models.Activity.elevation_gain,
                "vo2_max": models.Activity.vo2_max,
                "rpe": models.Activity.rpe,
                "avg_cadence": models.Activity.avg_cadence,
            }
            
            if column not in column_map:
                continue
            
            attr = column_map[column]
            
            for op, value in condition.items():
                if op == "gt":
                    query = query.filter(attr > value)
                elif op == "lt":
                    query = query.filter(attr < value)
                elif op == "gte":
                    query = query.filter(attr >= value)
                elif op == "lte":
                    query = query.filter(attr <= value)
                elif op == "eq":
                    query = query.filter(attr == value)
                elif op == "is_not_null":
                    query = query.filter(attr.isnot(None))
        
        return query
    
    def _aggregate_results(self, activities: List[models.Activity], aggregations: List[str]) -> Dict:
        """Calculate aggregations from activity list with fitness normalization."""
        if not activities:
            return {"count": 0}
        
        result = {"count": len(activities)}
        
        # Distance
        distances = [a.distance for a in activities if a.distance]
        if distances:
            result["total_distance_km"] = sum(distances) / 1000
            result["avg_distance_km"] = (sum(distances) / len(distances)) / 1000
        
        # Duration and Pace
        durations = [a.duration for a in activities if a.duration]
        if distances and durations:
            total_dist = sum(distances) / 1000  # km
            total_dur = sum(durations) / 60  # minutes
            if total_dist > 0:
                avg_pace_min = total_dur / total_dist
                result["avg_pace"] = f"{int(avg_pace_min)}:{int((avg_pace_min % 1) * 60):02d}"
        
        # HR
        hrs = [a.average_hr for a in activities if a.average_hr]
        if hrs:
            result["avg_hr"] = int(sum(hrs) / len(hrs))
        
        max_hrs = [a.max_hr for a in activities if a.max_hr]
        if max_hrs:
            result["avg_max_hr"] = int(sum(max_hrs) / len(max_hrs))
        
        # Weather
        temps = [a.weather_temp for a in activities if a.weather_temp]
        if temps:
            result["avg_temp"] = round(sum(temps) / len(temps), 1)
        
        # Elevation
        elevs = [a.elevation_gain for a in activities if a.elevation_gain]
        if elevs:
            result["avg_elevation"] = int(sum(elevs) / len(elevs))
        
        # VO2MAX CONTEXT (for fitness normalization)
        vo2s = [(a.vo2_max, a.local_start_date) for a in activities if a.vo2_max]
        if vo2s:
            result["avg_vo2max"] = int(sum(v[0] for v in vo2s) / len(vo2s))
            result["vo2max_range"] = f"{min(v[0] for v in vo2s)}-{max(v[0] for v in vo2s)}"
            
            # Check if VO2max changed significantly during this period
            sorted_vo2 = sorted(vo2s, key=lambda x: x[1])
            if len(sorted_vo2) >= 2:
                start_vo2 = sorted_vo2[0][0]
                end_vo2 = sorted_vo2[-1][0]
                change = end_vo2 - start_vo2
                result["vo2max_change"] = change
                if abs(change) >= 2:
                    result["fitness_note"] = f"Bu dÃ¶nemde VO2max {start_vo2}â†’{end_vo2} ({'+' if change > 0 else ''}{change}) deÄŸiÅŸmiÅŸ"
        
        # TEMPORAL ANALYSIS
        dates = [a.local_start_date for a in activities if a.local_start_date]
        if dates:
            oldest = min(dates)
            newest = max(dates)
            result["date_range"] = f"{oldest} - {newest}"
            result["span_days"] = (newest - oldest).days
            
            # Group by quarters for trend visibility
            from collections import defaultdict
            quarters = defaultdict(list)
            for a in activities:
                if a.local_start_date and a.average_hr:
                    q = f"{a.local_start_date.year}-Q{(a.local_start_date.month - 1) // 3 + 1}"
                    quarters[q].append({
                        "hr": a.average_hr,
                        "vo2": a.vo2_max,
                        "date": a.local_start_date
                    })
            
            if len(quarters) > 1:
                quarter_stats = []
                for q, runs in sorted(quarters.items()):
                    avg_hr = int(sum(r["hr"] for r in runs) / len(runs))
                    vo2s_q = [r["vo2"] for r in runs if r["vo2"]]
                    avg_vo2 = int(sum(vo2s_q) / len(vo2s_q)) if vo2s_q else None
                    quarter_stats.append({
                        "quarter": q,
                        "runs": len(runs),
                        "avg_hr": avg_hr,
                        "avg_vo2": avg_vo2
                    })
                result["quarterly_breakdown"] = quarter_stats
        
        # Sample activities for context
        result["sample_activities"] = [
            {
                "name": a.activity_name,
                "date": str(a.local_start_date),
                "distance_km": round((a.distance or 0) / 1000, 1),
                "avg_hr": a.average_hr,
                "temp": a.weather_temp,
                "vo2max": a.vo2_max
            }
            for a in activities[:5]
        ]
        
        return result
    
    def _generate_response(self, question: str, plan: QueryPlan, results: Dict) -> str:
        """Generate natural language response from query results."""
        main = results["main"]
        comp = results.get("comparison")
        
        # Build context for LLM
        context_lines = [f"# SORGU: {plan.description}"]
        
        context_lines.append(f"\n## ANA SONUÃ‡LAR")
        context_lines.append(f"Bulunan aktivite sayÄ±sÄ±: {main['count']}")
        
        if main.get("avg_distance_km"):
            context_lines.append(f"Ortalama mesafe: {main['avg_distance_km']:.1f} km")
        if main.get("avg_pace"):
            context_lines.append(f"Ortalama pace: {main['avg_pace']}/km")
        if main.get("avg_hr"):
            context_lines.append(f"Ortalama nabÄ±z: {main['avg_hr']} bpm")
        if main.get("avg_temp"):
            context_lines.append(f"Ortalama sÄ±caklÄ±k: {main['avg_temp']}Â°C")
        if main.get("avg_elevation"):
            context_lines.append(f"Ortalama yÃ¼kseliÅŸ: {main['avg_elevation']}m")
        
        # VO2MAX FITNESS CONTEXT
        if main.get("avg_vo2max"):
            context_lines.append(f"\n## FÄ°TNESS BAÄLAMI (Ã–NEMLÄ°!)")
            context_lines.append(f"VO2max aralÄ±ÄŸÄ±: {main.get('vo2max_range', 'N/A')}")
            if main.get("fitness_note"):
                context_lines.append(f"âš ï¸ {main['fitness_note']}")
            if main.get("date_range"):
                context_lines.append(f"Tarih aralÄ±ÄŸÄ±: {main['date_range']}")
        
        # QUARTERLY BREAKDOWN (for temporal normalization)
        if main.get("quarterly_breakdown"):
            context_lines.append(f"\n## DÃ–NEMSEL KIYASLAMA (Fitness-Normalized)")
            for q in main["quarterly_breakdown"]:
                vo2_str = f", VO2max={q['avg_vo2']}" if q.get('avg_vo2') else ""
                context_lines.append(f"- {q['quarter']}: {q['runs']} koÅŸu, Ort HR={q['avg_hr']}{vo2_str}")
        
        if main.get("sample_activities"):
            context_lines.append(f"\n## Ã–RNEK AKTÄ°VÄ°TELER")
            for act in main["sample_activities"]:
                vo2_str = f", VO2={act.get('vo2max')}" if act.get('vo2max') else ""
                context_lines.append(f"- {act['date']}: {act['name']} - {act['distance_km']}km, HR {act.get('avg_hr', 'N/A')}{vo2_str}")
        
        if comp:
            context_lines.append(f"\n## KARÅILAÅTIRMA GRUBU")
            context_lines.append(f"Aktivite sayÄ±sÄ±: {comp['count']}")
            if comp.get("avg_pace"):
                context_lines.append(f"Ortalama pace: {comp['avg_pace']}/km")
            if comp.get("avg_hr"):
                context_lines.append(f"Ortalama nabÄ±z: {comp['avg_hr']} bpm")
            if comp.get("avg_vo2max"):
                context_lines.append(f"Ortalama VO2max: {comp['avg_vo2max']}")
            if comp.get("quarterly_breakdown"):
                context_lines.append(f"\n### KarÅŸÄ±laÅŸtÄ±rma DÃ¶nemsel:")
                for q in comp["quarterly_breakdown"]:
                    context_lines.append(f"- {q['quarter']}: {q['runs']} koÅŸu, HR={q['avg_hr']}")
        
        context = "\n".join(context_lines)
        
        prompt = f"""Sen bir koÅŸu koÃ§usun. KullanÄ±cÄ±nÄ±n sorusunu gerÃ§ek verilerle cevapla.

# KULLANICI SORUSU
{question}

# VERÄ°TABANINDAN Ã‡EKILEN VERÄ°
{context}

# TALÄ°MAT
- GerÃ§ek rakamlara dayalÄ± cevap ver
- VO2max deÄŸiÅŸimini MUTLAKA hesaba kat - aynÄ± HR farklÄ± fitness seviyelerinde farklÄ± anlam taÅŸÄ±r
- DÃ¶nemsel karÅŸÄ±laÅŸtÄ±rma yap (Q1 vs Q4 gibi) - sporcunun geliÅŸimini gÃ¶ster
- Sadece basit ortalama VERME, fitness-normalized yorum yap
- KÄ±sa ve Ã¶z ol (150-200 kelime)
- Emoji kullan ğŸ˜Š
"""
        
        response = self.llm.generate(prompt, max_tokens=500)
        return response.text
